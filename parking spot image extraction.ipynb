{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5bnW9DJY0HZ",
        "outputId": "d1f6bf0c-3899-4585-80f8-c8d65314b1a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "def canny_edge_detection(image, low_threshold, high_threshold):\n",
        "    # Convert image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    cv2.imwrite('grayimg.png', gray)\n",
        "    # Apply Gaussian blur to reduce noise\n",
        "    blurred = cv2.GaussianBlur(gray, (11,11), 0,0)\n",
        "\n",
        "    cv2.imwrite('blurimg.png', blurred)\n",
        "\n",
        "    # Apply Canny edge detection\n",
        "    edges = cv2.Canny(blurred, low_threshold, high_threshold)\n",
        "\n",
        "\n",
        "\n",
        "    return edges\n",
        "\n",
        "# Read image\n",
        "image = cv2.imread('/content/2012-10-111.jpg')\n",
        "\n",
        "# Define thresholds\n",
        "low_threshold = 50\n",
        "high_threshold = 180\n",
        "\n",
        "# Apply Canny edge detection\n",
        "edges = canny_edge_detection(image, low_threshold, high_threshold)\n",
        "\n",
        "# Display the result\n",
        "cv2.imwrite('detectedEdges.png', edges)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMVAE3Io2Wsa",
        "outputId": "f4b799fa-5d5c-460b-868f-a696a9207c4d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import numpy as np\n",
        "# Apply Hough Line Transform\n",
        "lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=60, minLineLength=10, maxLineGap=25)\n",
        "\n",
        "# Draw detected lines on a blank image\n",
        "height, width = edges.shape[:2]\n",
        "blank_image = np.zeros((height, width, 3), dtype=np.uint8)\n",
        "\n",
        "if lines is not None:\n",
        "    for line in lines:\n",
        "        x1, y1, x2, y2 = line[0]\n",
        "\n",
        "        cv2.line(blank_image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "# Display the result\n",
        "cv2.imwrite('detectedLines.png', blank_image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeS2JUpujtyP",
        "outputId": "a3973e3f-82ac-4b8b-ef92-42748557a8e9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "zero_slope_lines=[]\n",
        "if lines is not None:\n",
        "    for line in lines:\n",
        "        x1, y1, x2, y2 = line[0]\n",
        "                # Calculate slop\n",
        "        slope = (y2 - y1) / (x2 - x1) if (x2 - x1) != 0 else np.inf\n",
        "        if slope >=0 and slope<1:\n",
        "          zero_slope_lines.append(line)\n",
        "\n",
        "\n",
        "\n",
        "for line in zero_slope_lines:\n",
        "  x1, y1, x2, y2 = line[0]\n",
        "  cv2.line(blank_image, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
        "\n",
        "\n",
        "\n",
        "# Display the result\n",
        "cv2.imwrite('detectedLineswithzeroslope.png', blank_image)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wb4CBSbyEPTP",
        "outputId": "816917fb-9d91-46bd-8151-e32ed741452b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[41, 89, 90, 109, 130, 180, 180, 221, 259, 286, 314, 322, 383, 429, 433, 474, 530, 541]\n"
          ]
        }
      ],
      "source": [
        "# Extract x-coordinates of endpoints of lines\n",
        "x_coords = []\n",
        "for line in zero_slope_lines:\n",
        "  x1, _, x2, _ = line[0]\n",
        "  x_coords.append(x1)\n",
        "  x_coords.append(x2)\n",
        "\n",
        "# Sort x-coordinates\n",
        "x_coords.sort()\n",
        "print(x_coords)\n",
        "# Identify main parking lanes\n",
        "main_parking_lanes = []\n",
        "if len(x_coords) > 0:\n",
        "    main_parking_lanes.append(x_coords[0])\n",
        "    for i in range(1, len(x_coords)):\n",
        "        if x_coords[i] - x_coords[i-1] > 20:  # Assume a gap of at least 10 pixels indicates a new lane\n",
        "            main_parking_lanes.append(x_coords[i])\n",
        "\n",
        "# Divide the space between each pair of detected main parking lanes into equal segments\n",
        "parking_spots = []\n",
        "for i in range(len(main_parking_lanes) - 1):\n",
        "    start_x = main_parking_lanes[i]\n",
        "    end_x = main_parking_lanes[i + 1]\n",
        "    num_segments = 3  # Adjust the number of segments as needed\n",
        "    segment_width = (end_x - start_x) // num_segments\n",
        "    for j in range(num_segments):\n",
        "        parking_spots.append((start_x + j * segment_width, start_x + (j + 1) * segment_width))\n",
        "\n",
        "# Save the coordinates of each parking spot\n",
        "with open('parking_spot_coordinates.txt', 'w') as file:\n",
        "    for idx, spot in enumerate(parking_spots):\n",
        "        file.write(f'Parking spot {idx + 1}: {spot}\\n')\n",
        "        # Draw rectangles around parking spots on the image\n",
        "        cv2.rectangle(image, (spot[0], 170), (spot[1], 210), (0, 255, 0), 2)\n",
        "        cv2.rectangle(image, (spot[0], 135), (spot[1], 165), (0, 255, 0), 2)\n",
        "        cv2.rectangle(image, (spot[0], 245), (spot[1], 275), (0, 255, 0), 2)\n",
        "        cv2.rectangle(image, (spot[0], 290), (spot[1], 320), (0, 255, 0), 2)\n",
        "        cv2.rectangle(image, (spot[0], 370), (spot[1], 420), (0, 255, 0), 2)\n",
        "\n",
        "# Save the result image\n",
        "cv2.imwrite('parking_spots_marked.png', image)\n",
        "\n",
        "# Read image\n",
        "img = cv2.imread('/content/2012-10-111.jpg')\n",
        "i = 1\n",
        "# Open the text file containing pairs of x coordinates\n",
        "with open('/content/parking_spot_coordinates.txt', 'r') as file:\n",
        "    for line in file:\n",
        "        values_str = line.split(\"(\")[1].split(\")\")[0]\n",
        "        x1, x2 = map(int, values_str.split(\",\"))\n",
        "\n",
        "        # Set default values for y-coordinate and dimensions\n",
        "        y = 170  # Default y-coordinate\n",
        "        width = abs(x2 - x1)  # Width is the difference between x2 and x1\n",
        "        height = 40  # Default height\n",
        "\n",
        "        # Extract the region of interest (ROI)\n",
        "        roi = img[y:y+height, x1:x2]\n",
        "\n",
        "        # Save the extracted ROI as an image\n",
        "        if width>13:\n",
        "          cv2.imwrite('empty_' + str(i) + '.png', roi)  # Save as 'empty_1.png', 'empty_2.png', etc.\n",
        "        i += 1\n",
        "\n",
        "# Destroy all OpenCV windows\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read image\n",
        "img = cv2.imread('/content/2012-09-14_17_36_31.jpg')\n",
        "i = 1\n",
        "# Open the text file containing pairs of x coordinates\n",
        "with open('/content/parking_spot_coordinates.txt', 'r') as file:\n",
        "    for line in file:\n",
        "        values_str = line.split(\"(\")[1].split(\")\")[0]\n",
        "        x1, x2 = map(int, values_str.split(\",\"))\n",
        "\n",
        "        # Set default values for y-coordinate and dimensions\n",
        "        y = 170  # Default y-coordinate\n",
        "        width = abs(x2 - x1)  # Width is the difference between x2 and x1\n",
        "        height = 40  # Default height\n",
        "\n",
        "        # Extract the region of interest (ROI)\n",
        "        roi = img[y:y+height, x1:x2]\n",
        "\n",
        "        # Save the extracted ROI as an image\n",
        "        if width>13:\n",
        "          cv2.imwrite('empty_' + str(i) + '.png', roi)  # Save as 'empty_1.png', 'empty_2.png', etc.\n",
        "        i += 1\n",
        "\n",
        "# Destroy all OpenCV windows\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "7NyD2tVsrtaO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "0a355266-69e5-492a-d92d-c6c1a8eff1af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'NoneType' object is not subscriptable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-c3637b70a5a5>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# Extract the region of interest (ROI)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mroi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# Save the extracted ROI as an image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_AgVtcCsEkDM"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}